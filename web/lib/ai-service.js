/**
 * Servicio de IA para troceado autom√°tico de tareas
 * Soporta: Templates (local) + OpenAI + Anthropic
 */

import { templateBreakdown, TEMPLATES } from './templates.js';

// Prompt base para troceado con IA
const BREAKDOWN_PROMPT = `Eres un Coach de Productividad especializado en Project Management.
Tu usuario quiere completar un proyecto grande.

PROYECTO: {title}
DESCRIPCI√ìN: {description}
CATEGOR√çA: {category} (trabajo/contenido/aprender/clientes)
ESTRATEGIA: {strategy} (goteo=1 paso/semana, batching=sprint intensivo)

INSTRUCCIONES:
1. Divide este proyecto en m√°ximo 7 micro-pasos.
2. Cada paso debe:
   - Tomar m√°ximo 45-60 minutos
   - Terminar con algo TANGIBLE (no "avanzar" o "continuar")
   - Ser espec√≠fico y accionable
   - Tener un entregable claro

3. Para estrategia "goteo": Los pasos son para TODO el proyecto (varias semanas)
4. Para estrategia "batching": Los pasos son intensivos (semanas seguidas)

FORMATO DE RESPUESTA (solo JSON, sin texto adicional):
{
  "milestones": [
    {
      "title": "T√≠tulo corto del paso",
      "description": "Descripci√≥n de qu√© hacer y qu√© resultado esperar",
      "time_estimate": 45
    }
  ],
  "reasoning": "Breve explicaci√≥n de por qu√© esta divisi√≥n tiene sentido"
}`;

/**
 * Servicio principal de troceado
 */
class AIService {
    /**
     * Genera troceado de tarea
     * @param {Object} params - Par√°metros del proyecto
     * @param {string} params.title - T√≠tulo del proyecto
     * @param {string} params.description - Descripci√≥n del proyecto
     * @param {string} params.category - Categor√≠a (trabajo, contenido, aprender, clientes)
     * @param {string} params.strategy - Estrategia (goteo, batching)
     * @param {string} params.templateId - Plantilla espec√≠fica seleccionada (opcional)
     * @param {boolean} params.useAI - Si usar IA real o templates
     * @param {string} params.apiProvider - Proveedor de IA (openai, anthropic)
     * @returns {Object} Milestones generados
     */
    static async breakdownTask(params) {
        const { useAI, apiProvider, templateId } = params;

        console.log('üîß AIService.breakdownTask called:', {
            useAI,
            apiProvider,
            templateId: templateId || 'auto',
            title: params.title
        });

        // MODO 1: Plantilla espec√≠fica seleccionada + modo r√°pido
        if (templateId && !useAI) {
            console.log('üìã Usando plantilla espec√≠fica:', templateId);
            return this.useSpecificTemplate(templateId, params);
        }

        // MODO 2: Plantilla espec√≠fica + IA (h√≠brido)
        if (templateId && useAI) {
            console.log('üé® Modo h√≠brido: plantilla base + personalizaci√≥n con IA');
            const baseTemplate = this.useSpecificTemplate(templateId, params);
            return await this.enrichTemplateWithAI(baseTemplate, params, apiProvider);
        }

        // MODO 3: Auto-detectar plantilla (comportamiento actual)
        if (!useAI) {
            console.log('üìã Auto-detectando tipo y usando template');
            return this.templateBreakdown(params);
        }

        // MODO 4: IA pura (sin plantilla base)
        console.log('ü§ñ Generaci√≥n pura con IA');
        if (apiProvider === 'openai') {
            console.log('üü¢ Llamando a OpenAI...');
            return await this.openaiBreakdown(params);
        } else if (apiProvider === 'anthropic') {
            console.log('üü£ Llamando a Anthropic...');
            return await this.anthropicBreakdown(params);
        }

        // Fallback a templates si no hay proveedor v√°lido
        console.warn('‚ö†Ô∏è No hay proveedor v√°lido, fallback a templates');
        return this.templateBreakdown(params);
    }

    /**
     * Troceado con templates locales (r√°pido, sin API)
     */
    static templateBreakdown(params) {
        const result = templateBreakdown(params);
        result.ai_provider = 'template';
        result.model = 'templates-locales';
        return result;
    }

    /**
     * Usa una plantilla espec√≠fica seleccionada por el usuario
     */
    static useSpecificTemplate(templateId, params) {
        const template = TEMPLATES[templateId];

        if (!template) {
            console.warn('‚ö†Ô∏è Plantilla no encontrada:', templateId, '- fallback a auto-detect');
            return this.templateBreakdown(params);
        }

        console.log('‚úÖ Plantilla encontrada:', templateId, `(${template.length} pasos)`);

        const milestones = template.map((m, idx) => ({
            ...m,
            order: idx + 1
        }));

        // Ajustar seg√∫n estrategia
        if (params.strategy === 'batching') {
            milestones.forEach(m => {
                m.time_estimate = Math.min(m.time_estimate, 45);
            });
        }

        return {
            generated_milestones: milestones,
            template_used: templateId,
            detected_type: templateId.split(':')[1] || 'custom',
            reasoning: `Plantilla "${templateId}" seleccionada manualmente. ${milestones.length} pasos predefinidos listos para editar.`,
            ai_provider: 'template',
            model: 'templates-locales'
        };
    }

    /**
     * Enriquece una plantilla base con personalizaci√≥n de IA
     */
    static async enrichTemplateWithAI(baseTemplate, params, apiProvider) {
        const { title, description } = params;

        // Construir prompt especial para enriquecer plantilla
        const enrichPrompt = `Tienes esta plantilla base de ${baseTemplate.generated_milestones.length} pasos:

${baseTemplate.generated_milestones.map((m, i) =>
    `${i + 1}. ${m.title} (${m.time_estimate} min)\n   ‚Üí ${m.description}`
).join('\n\n')}

PROYECTO ESPEC√çFICO: "${title}"
${description ? `CONTEXTO ADICIONAL: ${description}` : ''}

TAREA: Personaliza esta plantilla para el proyecto espec√≠fico.
- Mant√©n la ESTRUCTURA (mismo n√∫mero de pasos, mismo orden)
- Ajusta los T√çTULOS para que mencionen el contexto espec√≠fico del proyecto
- Mejora las DESCRIPCIONES con detalles relevantes al proyecto
- Mant√©n los TIEMPOS estimados similares (¬±10 minutos)
- Cada paso debe terminar con un ENTREGABLE concreto

Ejemplo de personalizaci√≥n:
- Gen√©rico: "Escribir introducci√≥n" ‚Üí Espec√≠fico: "Escribir introducci√≥n sobre Google Ads"
- Gen√©rico: "Investigar tema" ‚Üí Espec√≠fico: "Investigar c√≥mo funcionan las pujas en Google Ads"

RESPONDE SOLO CON JSON V√ÅLIDO:
{
  "milestones": [
    {
      "title": "t√≠tulo personalizado del paso",
      "description": "descripci√≥n mejorada con detalles espec√≠ficos",
      "time_estimate": 45
    }
  ],
  "reasoning": "Breve explicaci√≥n de c√≥mo se personaliz√≥"
}`;

        try {
            if (apiProvider === 'openai') {
                const apiKey = process.env.OPENAI_API_KEY;
                if (!apiKey) {
                    console.log('‚ö†Ô∏è Sin API key de OpenAI, usando plantilla base');
                    return baseTemplate;
                }

                const { default: OpenAI } = await import('openai');
                const openai = new OpenAI({ apiKey });

                console.log('üé® Enriqueciendo plantilla con OpenAI...');
                const response = await openai.chat.completions.create({
                    model: 'gpt-4o-mini',
                    messages: [
                        {
                            role: 'system',
                            content: 'Eres un coach de productividad. Personalizas plantillas de tareas. Responde SOLO con JSON v√°lido, sin texto adicional.'
                        },
                        { role: 'user', content: enrichPrompt }
                    ],
                    temperature: 0.7,
                    max_tokens: 1200
                });

                const content = response.choices[0]?.message?.content;
                if (!content) {
                    throw new Error('Respuesta vac√≠a de OpenAI');
                }

                console.log('‚úÖ Plantilla personalizada con IA');
                const result = this.parseAIResponse(content);

                return {
                    ...result,
                    template_used: baseTemplate.template_used,
                    detected_type: baseTemplate.detected_type,
                    ai_provider: 'hybrid',
                    model: 'template+gpt-4o-mini',
                    reasoning: `Plantilla "${baseTemplate.template_used}" personalizada con IA. ${result.reasoning || 'Pasos adaptados al proyecto.'}`
                };
            } else if (apiProvider === 'anthropic') {
                // Similar para Anthropic...
                console.log('‚ö†Ô∏è Anthropic no implementado a√∫n, usando plantilla base');
                return baseTemplate;
            }

            // Si no hay proveedor v√°lido
            console.log('‚ö†Ô∏è Sin proveedor de IA v√°lido, usando plantilla base');
            return baseTemplate;

        } catch (error) {
            console.error('‚ùå Error enriqueciendo con IA:', error.message);

            // Si es error de cr√©ditos, informar espec√≠ficamente
            if (error.message.includes('429') || error.message.includes('quota')) {
                console.log('‚ö†Ô∏è Sin cr√©ditos en OpenAI, usando plantilla base');
                return {
                    ...baseTemplate,
                    reasoning: baseTemplate.reasoning + ' (IA no disponible: sin cr√©ditos)'
                };
            }

            // Para otros errores, usar plantilla base
            console.log('‚ö†Ô∏è Error inesperado, usando plantilla base sin personalizaci√≥n');
            return {
                ...baseTemplate,
                reasoning: baseTemplate.reasoning + ' (Error en personalizaci√≥n IA)'
            };
        }
    }

    /**
     * Construye el prompt para la IA
     */
    static buildPrompt(params) {
        return BREAKDOWN_PROMPT
            .replace('{title}', params.title)
            .replace('{description}', params.description || 'Sin descripci√≥n adicional')
            .replace('{category}', params.category)
            .replace('{strategy}', params.strategy);
    }

    /**
     * Parsea la respuesta de la IA
     */
    static parseAIResponse(content) {
        try {
            // Intentar extraer JSON del contenido
            const jsonMatch = content.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
                const parsed = JSON.parse(jsonMatch[0]);

                // Validar estructura
                if (!parsed.milestones || !Array.isArray(parsed.milestones)) {
                    throw new Error('Respuesta sin milestones v√°lidos');
                }

                // A√±adir order a cada milestone
                const milestones = parsed.milestones.map((m, idx) => ({
                    title: m.title || `Paso ${idx + 1}`,
                    description: m.description || '',
                    time_estimate: m.time_estimate || 45,
                    order: idx + 1
                }));

                return {
                    generated_milestones: milestones,
                    reasoning: parsed.reasoning || 'Generado con IA',
                    ai_provider: 'ai'
                };
            }

            throw new Error('No se encontr√≥ JSON en la respuesta');
        } catch (error) {
            console.error('Error parseando respuesta IA:', error);
            throw new Error('Error procesando respuesta de IA: ' + error.message);
        }
    }

    /**
     * Troceado con OpenAI
     */
    static async openaiBreakdown(params) {
        const apiKey = process.env.OPENAI_API_KEY;

        if (!apiKey) {
            throw new Error('OPENAI_API_KEY no configurada. A√±√°dela al archivo .env');
        }

        try {
            // Importaci√≥n din√°mica para no requerir el paquete si no se usa
            const { default: OpenAI } = await import('openai');
            const openai = new OpenAI({ apiKey });

            const prompt = this.buildPrompt(params);

            const response = await openai.chat.completions.create({
                model: 'gpt-4o-mini', // Modelo r√°pido y econ√≥mico
                messages: [
                    { role: 'system', content: 'Eres un coach de productividad. Responde SOLO con JSON v√°lido.' },
                    { role: 'user', content: prompt }
                ],
                temperature: 0.7,
                max_tokens: 1000
            });

            const content = response.choices[0]?.message?.content;
            if (!content) {
                throw new Error('Respuesta vac√≠a de OpenAI');
            }

            console.log('‚úÖ OpenAI: Pasos generados exitosamente');
            const result = this.parseAIResponse(content);
            result.ai_provider = 'openai';
            result.model = 'gpt-4o-mini';
            return result;

        } catch (error) {
            console.error('‚ùå Error OpenAI:', error.message);

            // Si falla la IA, fallback a templates
            if (error.message.includes('API key') || error.message.includes('401')) {
                throw new Error('API key de OpenAI inv√°lida o expirada');
            }

            // Error 429: Sin cr√©ditos
            if (error.message.includes('429') || error.message.includes('quota') || error.message.includes('insufficient_quota')) {
                console.log('‚ö†Ô∏è Sin cr√©ditos en OpenAI, usando templates');
                const fallback = this.templateBreakdown(params);
                fallback.reasoning += ' (IA no disponible: sin cr√©ditos en OpenAI)';
                fallback.ai_provider = 'template';
                fallback.model = 'templates-locales';
                return fallback;
            }

            // Otros errores: Fallback silencioso a templates
            console.log('‚ö†Ô∏è Fallback a templates por error de OpenAI:', error.message);
            const fallback = this.templateBreakdown(params);
            fallback.reasoning += ` (Fallback: ${error.message.substring(0, 100)})`;
            return fallback;
        }
    }

    /**
     * Troceado con Anthropic/Claude
     */
    static async anthropicBreakdown(params) {
        const apiKey = process.env.ANTHROPIC_API_KEY;

        if (!apiKey) {
            throw new Error('ANTHROPIC_API_KEY no configurada. A√±√°dela al archivo .env');
        }

        try {
            // Importaci√≥n din√°mica
            const { default: Anthropic } = await import('@anthropic-ai/sdk');
            const anthropic = new Anthropic({ apiKey });

            const prompt = this.buildPrompt(params);

            const response = await anthropic.messages.create({
                model: 'claude-3-haiku-20240307', // Modelo r√°pido y econ√≥mico
                max_tokens: 1000,
                messages: [
                    { role: 'user', content: prompt }
                ],
                system: 'Eres un coach de productividad. Responde SOLO con JSON v√°lido, sin texto adicional.'
            });

            const content = response.content[0]?.text;
            if (!content) {
                throw new Error('Respuesta vac√≠a de Anthropic');
            }

            const result = this.parseAIResponse(content);
            result.ai_provider = 'anthropic';
            return result;

        } catch (error) {
            console.error('Error Anthropic:', error);

            if (error.message.includes('API key') || error.message.includes('401')) {
                throw new Error('API key de Anthropic inv√°lida o expirada');
            }

            // Fallback silencioso a templates
            console.log('Fallback a templates por error de Anthropic');
            const fallback = this.templateBreakdown(params);
            fallback.reasoning += ' (Fallback: error en Anthropic)';
            return fallback;
        }
    }

    /**
     * Verifica qu√© proveedores de IA est√°n disponibles
     */
    static getAvailableProviders() {
        const providers = ['template']; // Siempre disponible

        if (process.env.OPENAI_API_KEY) {
            providers.push('openai');
        }

        if (process.env.ANTHROPIC_API_KEY) {
            providers.push('anthropic');
        }

        return providers;
    }
}

export default AIService;
